{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import word2vec\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "from opencc import OpenCC\n",
    "\n",
    "cc = OpenCC('s2t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = open('D://NLP/wiki_zh_2019/wiki_zh/AA/wiki_00', \"r\", encoding=\"utf-8\")\n",
    "\n",
    "id_list    = []\n",
    "url_list   = []\n",
    "title_list = []\n",
    "text_list  = []\n",
    "\n",
    "lines = fd.readlines()\n",
    "for line in lines:\n",
    "    line = line.strip('')\n",
    "\n",
    "    id_value    = line.split(', ')[0].strip('{').split(' ')[1].strip('\"')\n",
    "    url_value   = line.split(', ')[1].split(' ')[1].strip('\"')\n",
    "    title_value = cc.convert(str(line.split(', ')[2].split(' ')[1].strip('\"')))\n",
    "    text_value  = cc.convert(str(line.split(', ')[3].split(': \"')[1].strip('\"\\'}\\n')))\n",
    "    \n",
    "    id_list.append(id_value)\n",
    "    url_list.append(url_value)\n",
    "    title_list.append(title_value)\n",
    "    text_list.append(text_value)\n",
    "\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(filename, word_list):\n",
    "    with open(filename, 'r', encoding=\"utf-8\") as f:\n",
    "        stop_words = f.read().split('\\n')\n",
    "        \n",
    "    stop_words.append('\\n')\n",
    "    stop_words.append('\\n\\n')\n",
    "    stop_words.append('\\n\\n\\n')\n",
    "    stop_words.append('\\n\\n\\n\\n')\n",
    "    stop_words.append('\\\\')\n",
    "    stop_words.append('/')\n",
    "    stop_words.append(' ')\n",
    "    stop_words.append('n')\n",
    "    stop_words.append('{')\n",
    "    stop_words.append('}')\n",
    "    stop_words.append('－')\n",
    "    \n",
    "    new_list = []\n",
    "    \n",
    "    for word in word_list:\n",
    "        if word not in stop_words:\n",
    "            new_list.append(word)\n",
    "    \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                                      13\n",
      "url                 https://zh.wikipedia.org/wiki?curid=13\n",
      "title                                                   數學\n",
      "text     [數學, 數學, 利用, 符號, 語言, 研究, 數量, 結構, 變化, 空間, 概念, 一...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "cut_text_list = []\n",
    "#print(text_list[0])\n",
    "\n",
    "for text in text_list:\n",
    "    text = jieba.lcut(text)\n",
    "    text = remove_stop_words('stop.txt', text)\n",
    "    \n",
    "    cut_text_list.append(text)\n",
    "\n",
    "\n",
    "wiki_dict = {'id': id_list, 'url': url_list, 'title': title_list, 'text': cut_text_list} \n",
    "wiki_df = pd.DataFrame(wiki_dict)\n",
    "\n",
    "print(wiki_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy.__version__\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = Word2Vec(cut_text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('領域', 0.9992307424545288), ('科學', 0.9990180730819702), ('研究', 0.9989759922027588), ('應用', 0.9988747835159302), ('物理', 0.9988300800323486), ('方法', 0.9987704753875732), ('學科', 0.9987117052078247), ('生物', 0.9986189007759094), ('理論', 0.9985644221305847), ('心理', 0.9984905123710632)]\n"
     ]
    }
   ],
   "source": [
    "similar_word = test_model.wv.most_similar('數學', topn=10)\n",
    "print(similar_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D://NLP/wiki_zh_2019/wiki_zh/AA/wiki_00\n",
      "D://NLP/wiki_zh_2019/wiki_zh/AA/wiki_01\n",
      "D://NLP/wiki_zh_2019/wiki_zh/AA/wiki_02\n",
      "D://NLP/wiki_zh_2019/wiki_zh/AA/wiki_03\n",
      "D://NLP/wiki_zh_2019/wiki_zh/AA/wiki_04\n",
      "D://NLP/wiki_zh_2019/wiki_zh/AB/wiki_00\n",
      "D://NLP/wiki_zh_2019/wiki_zh/AB/wiki_01\n",
      "D://NLP/wiki_zh_2019/wiki_zh/AB/wiki_02\n",
      "D://NLP/wiki_zh_2019/wiki_zh/AB/wiki_03\n",
      "D://NLP/wiki_zh_2019/wiki_zh/AB/wiki_04\n",
      "[('邏輯', 0.9596030116081238), ('理論', 0.9572277069091797), ('分析', 0.95585036277771), ('學中', 0.9398724436759949), ('物理', 0.9390361309051514), ('純數學', 0.9356193542480469), ('聲學', 0.9312252402305603), ('知識', 0.9310800433158875), ('語言學', 0.9308790564537048), ('模型', 0.9295468330383301)]\n"
     ]
    }
   ],
   "source": [
    "#file_prefix = ['AA/', 'AB/', 'AC/', 'AD/', 'AE/', 'AF/', 'AG/', 'AH/', 'AI/', 'AJ/', 'AK/', 'AL/', 'AM/']\n",
    "file_prefix = ['AA/', 'AB/']\n",
    "\n",
    "\n",
    "v2_id_list    = []\n",
    "v2_url_list   = []\n",
    "v2_title_list = []\n",
    "v2_text_list  = []\n",
    "\n",
    "\n",
    "for prefix in file_prefix:\n",
    "    for i in range(0, 5):\n",
    "    #for i in range(0, 100):\n",
    "        fn = 'D://NLP/wiki_zh_2019/wiki_zh/' + prefix + 'wiki_' + str(\"{:02}\".format(i))\n",
    "        print(fn)\n",
    "        \n",
    "        fd = open(fn, \"r\", encoding=\"utf-8\")\n",
    "        \n",
    "        lines = fd.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip('')\n",
    "\n",
    "            id_value    = line.split(', ')[0].strip('{').split(' ')[1].strip('\"')\n",
    "            url_value   = line.split(', ')[1].split(' ')[1].strip('\"')\n",
    "            title_value = cc.convert(str(line.split(', ')[2].split(' ')[1].strip('\"')))\n",
    "            text_value  = cc.convert(str(line.split(', ')[3].split(': \"')[1].strip('\"\\'}\\n')))\n",
    "\n",
    "            v2_id_list.append(id_value)\n",
    "            v2_url_list.append(url_value)\n",
    "            v2_title_list.append(title_value)\n",
    "            v2_text_list.append(text_value)\n",
    "\n",
    "        fd.close()\n",
    "\n",
    "        \n",
    "v2_cut_text_list = []\n",
    "#print(text_list[0])\n",
    "\n",
    "for text in v2_text_list:\n",
    "    text = jieba.lcut(text)\n",
    "    text = remove_stop_words('stop.txt', text)\n",
    "    \n",
    "    v2_cut_text_list.append(text)\n",
    "\n",
    "\n",
    "\n",
    "v2_test_model = Word2Vec(v2_cut_text_list)\n",
    "\n",
    "similar_word = v2_test_model.wv.most_similar('數學', topn=10)\n",
    "print(similar_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
